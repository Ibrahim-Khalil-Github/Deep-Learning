{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7854872,
          "sourceType": "datasetVersion",
          "datasetId": 4606977
        }
      ],
      "dockerImageVersionId": 30665,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Universal Transformer",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibrahim-Khalil-Github/Deep-Learning/blob/main/Universal_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4606977%2F7854872%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240417%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240417T081554Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D797a7c17d4bd88a98e1e02d4399c6402c42f730e527b65618758cca97e8fa70839bf72a2d31f7aedc1f8828ec114c1ba197d5ad2287283902af7c21c09a470860813f5d6926e45592ab0319736d61487133fac241056890703fd462abf0b6ce624d26d43df3605105207d284d1307f671e308e857894a2f494e45b5cf280e0def838c74c445704a79c24f26c8dfd521b37a56229e0fc8a62ce07e59ebfbeeda422d79de7bccc679c37d4b9bdc8d4db41557f42a61e5550014b114ce17787e7ca8e73915f7b113826654fe1ab40011111eda38d9903cca23a7875c1d38e78f47e81ecc3435a0a53b4f174f0b5665a152081b9c66b491132df07a5b6ca55ea9994'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "36SnvCkFINAN"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torch.utils.data\n",
        "import math\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:25:58.37037Z",
          "iopub.execute_input": "2024-03-20T16:25:58.370753Z",
          "iopub.status.idle": "2024-03-20T16:25:58.375695Z",
          "shell.execute_reply.started": "2024-03-20T16:25:58.370723Z",
          "shell.execute_reply": "2024-03-20T16:25:58.374783Z"
        },
        "trusted": true,
        "id": "EmHVenIoINAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_movie_conv = '/kaggle/input/dataset/movie_conversations.tsv'\n",
        "corpus_movie_lines = '/kaggle/input/dataset/movie_lines.tsv'\n",
        "max_len = 25"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:25:58.381846Z",
          "iopub.execute_input": "2024-03-20T16:25:58.382654Z",
          "iopub.status.idle": "2024-03-20T16:25:58.387159Z",
          "shell.execute_reply.started": "2024-03-20T16:25:58.382626Z",
          "shell.execute_reply": "2024-03-20T16:25:58.386373Z"
        },
        "trusted": true,
        "id": "3sUBdCMKINAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(corpus_movie_conv, 'r') as c:\n",
        "    conv = c.readlines()\n",
        "with open(corpus_movie_lines, 'r', encoding = 'utf8') as l:\n",
        "    lines = l.readlines()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:25:58.835326Z",
          "iopub.execute_input": "2024-03-20T16:25:58.836089Z",
          "iopub.status.idle": "2024-03-20T16:25:58.981121Z",
          "shell.execute_reply.started": "2024-03-20T16:25:58.836021Z",
          "shell.execute_reply": "2024-03-20T16:25:58.980119Z"
        },
        "trusted": true,
        "id": "vv3N4A0AINAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_dict = {}\n",
        "for line in lines:\n",
        "    objects = line.replace('\"', '').split('\\t')\n",
        "    lines_dict[objects[0]] = objects[-1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:25:58.984993Z",
          "iopub.execute_input": "2024-03-20T16:25:58.985309Z",
          "iopub.status.idle": "2024-03-20T16:25:59.375305Z",
          "shell.execute_reply.started": "2024-03-20T16:25:58.985282Z",
          "shell.execute_reply": "2024-03-20T16:25:59.374365Z"
        },
        "trusted": true,
        "id": "NgvQ1bxHINAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(string):\n",
        "    punctuations = '''!()-{}[];:'\"\\,<>./?@#$%^&*_~'''\n",
        "    no_punc = \"\"\n",
        "    for char in string:\n",
        "        if char not in punctuations:\n",
        "            no_punc = no_punc + char\n",
        "    return no_punc.lower()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:25:59.376673Z",
          "iopub.execute_input": "2024-03-20T16:25:59.377308Z",
          "iopub.status.idle": "2024-03-20T16:25:59.383492Z",
          "shell.execute_reply.started": "2024-03-20T16:25:59.377271Z",
          "shell.execute_reply": "2024-03-20T16:25:59.3824Z"
        },
        "trusted": true,
        "id": "N_0Pt6kfINAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = []\n",
        "\n",
        "for con in conv:\n",
        "\n",
        "    ids = eval(con.replace(' ', ',').split('\\t')[-1])\n",
        "\n",
        "    for i in range(len(ids)):\n",
        "\n",
        "        if i == len(ids)-1:\n",
        "            break\n",
        "\n",
        "        qa_pairs = []\n",
        "\n",
        "        first = remove_punc(lines_dict[ids[i]].strip())\n",
        "\n",
        "        second = remove_punc(lines_dict[ids[i+1]].strip())\n",
        "\n",
        "        qa_pairs.append(first.split()[:max_len])\n",
        "        qa_pairs.append(second.split()[:max_len])\n",
        "\n",
        "        pairs.append(qa_pairs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:25:59.384974Z",
          "iopub.execute_input": "2024-03-20T16:25:59.385554Z",
          "iopub.status.idle": "2024-03-20T16:26:08.984509Z",
          "shell.execute_reply.started": "2024-03-20T16:25:59.385519Z",
          "shell.execute_reply": "2024-03-20T16:26:08.983695Z"
        },
        "trusted": true,
        "id": "yhGr3LwRINAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq = Counter()\n",
        "for pair in pairs:\n",
        "    word_freq.update(pair[0])\n",
        "    word_freq.update(pair[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:08.986846Z",
          "iopub.execute_input": "2024-03-20T16:26:08.987171Z",
          "iopub.status.idle": "2024-03-20T16:26:10.216681Z",
          "shell.execute_reply.started": "2024-03-20T16:26:08.987145Z",
          "shell.execute_reply": "2024-03-20T16:26:10.215888Z"
        },
        "trusted": true,
        "id": "Eyc2isulINAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_word_freq = 5\n",
        "\n",
        "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
        "word_map = {k: v+1 for v, k in enumerate(words)}\n",
        "\n",
        "word_map['<unk>'] = len(word_map) + 1\n",
        "word_map['<start>'] = len(word_map) + 1\n",
        "word_map['<end>'] = len(word_map) + 1\n",
        "word_map['<pad>'] = 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:10.217686Z",
          "iopub.execute_input": "2024-03-20T16:26:10.217952Z",
          "iopub.status.idle": "2024-03-20T16:26:10.256898Z",
          "shell.execute_reply.started": "2024-03-20T16:26:10.21793Z",
          "shell.execute_reply": "2024-03-20T16:26:10.256119Z"
        },
        "trusted": true,
        "id": "f39NafQ2INAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/working/WORDMAP_corpus.json', 'w') as j:\n",
        "    json.dump(word_map, j)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:10.258132Z",
          "iopub.execute_input": "2024-03-20T16:26:10.25854Z",
          "iopub.status.idle": "2024-03-20T16:26:10.3031Z",
          "shell.execute_reply.started": "2024-03-20T16:26:10.258508Z",
          "shell.execute_reply": "2024-03-20T16:26:10.302365Z"
        },
        "trusted": true,
        "id": "fAmwb8r0INAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_question(words, word_map):\n",
        "    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']]*(max_len-len(words))\n",
        "    return enc_c"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:10.304097Z",
          "iopub.execute_input": "2024-03-20T16:26:10.30437Z",
          "iopub.status.idle": "2024-03-20T16:26:10.309407Z",
          "shell.execute_reply.started": "2024-03-20T16:26:10.304347Z",
          "shell.execute_reply": "2024-03-20T16:26:10.308493Z"
        },
        "trusted": true,
        "id": "Iu8FXsKkINAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_reply(words, word_map):\n",
        "    enc_c =[word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<end>']] + [word_map['<pad>']]*(max_len-len(words))\n",
        "    return enc_c"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:10.310599Z",
          "iopub.execute_input": "2024-03-20T16:26:10.310944Z",
          "iopub.status.idle": "2024-03-20T16:26:10.319369Z",
          "shell.execute_reply.started": "2024-03-20T16:26:10.310915Z",
          "shell.execute_reply": "2024-03-20T16:26:10.318399Z"
        },
        "trusted": true,
        "id": "DAlGsz38INAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_encoded = []\n",
        "\n",
        "for pair in pairs:\n",
        "    ques = encode_question(pair[0], word_map)\n",
        "    ans = encode_reply(pair[1], word_map)\n",
        "    pairs_encoded.append([ques, ans])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:10.320702Z",
          "iopub.execute_input": "2024-03-20T16:26:10.32104Z",
          "iopub.status.idle": "2024-03-20T16:26:13.522947Z",
          "shell.execute_reply.started": "2024-03-20T16:26:10.321014Z",
          "shell.execute_reply": "2024-03-20T16:26:13.522118Z"
        },
        "trusted": true,
        "id": "dSVCzteBINAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/working/pairs_encoded.json', 'w') as w:\n",
        "    json.dump(pairs_encoded, w)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:13.52425Z",
          "iopub.execute_input": "2024-03-20T16:26:13.524711Z",
          "iopub.status.idle": "2024-03-20T16:26:25.863311Z",
          "shell.execute_reply.started": "2024-03-20T16:26:13.524675Z",
          "shell.execute_reply": "2024-03-20T16:26:25.862343Z"
        },
        "trusted": true,
        "id": "IvBEVuYqINAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.pairs = json.load(open('/kaggle/working/pairs_encoded.json', 'r'))\n",
        "        self.dataset_size = len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        question = torch.LongTensor(self.pairs[i][0])\n",
        "        reply = torch.LongTensor(self.pairs[i][1])\n",
        "\n",
        "        return question, reply\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:25.864586Z",
          "iopub.execute_input": "2024-03-20T16:26:25.86488Z",
          "iopub.status.idle": "2024-03-20T16:26:25.871377Z",
          "shell.execute_reply.started": "2024-03-20T16:26:25.864856Z",
          "shell.execute_reply": "2024-03-20T16:26:25.870376Z"
        },
        "trusted": true,
        "id": "yqm4AZ_qINAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(Dataset(),\n",
        "                                           shuffle = True,\n",
        "                                           batch_size = 100,\n",
        "                                           pin_memory = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:25.872617Z",
          "iopub.execute_input": "2024-03-20T16:26:25.872956Z",
          "iopub.status.idle": "2024-03-20T16:26:28.986545Z",
          "shell.execute_reply.started": "2024-03-20T16:26:25.872904Z",
          "shell.execute_reply": "2024-03-20T16:26:28.98567Z"
        },
        "trusted": true,
        "id": "lUz-Uj11INAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(question, reply_input, reply_target):\n",
        "    def subsequent_mask(size):\n",
        "        mask = torch.tril(torch.ones(size, size)).type(dtype = torch.uint8)\n",
        "        return mask\n",
        "\n",
        "    question_mask = question!=0 #cuda\n",
        "    question_mask = question_mask.unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "    reply_input_mask = reply_input!=0 #cuda\n",
        "    reply_input_mask = reply_input_mask.unsqueeze(1)\n",
        "    reply_input_mask = reply_input_mask & subsequent_mask(reply_input.shape[-1]).type_as(reply_input_mask.data)\n",
        "    reply_input_mask = reply_input_mask.unsqueeze(1)\n",
        "    reply_target_mask = reply_target!=0\n",
        "\n",
        "    return question_mask, reply_input_mask, reply_target_mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:28.991517Z",
          "iopub.execute_input": "2024-03-20T16:26:28.992362Z",
          "iopub.status.idle": "2024-03-20T16:26:28.999236Z",
          "shell.execute_reply.started": "2024-03-20T16:26:28.992323Z",
          "shell.execute_reply": "2024-03-20T16:26:28.998324Z"
        },
        "trusted": true,
        "id": "eJcXybBfINAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, d_model, max_len = 50, num_layers = 6):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.d_model = d_model\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pe = self.create_positional_encoding(max_len, self.d_model)\n",
        "        self.te = self.create_positional_encoding(self.num_layers, self.d_model)\n",
        "\n",
        "    def create_positional_encoding(self, max_len, d_model):\n",
        "        pe = torch.zeros(max_len, d_model).cuda()\n",
        "\n",
        "        for pos in range(max_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos/(1000**(2*i/d_model)))\n",
        "                pe[pos, i+1] = math.cos(pos/(1000**(2*(i+1)/d_model)))\n",
        "\n",
        "        return pe\n",
        "\n",
        "    def forward(self, embedding, idx):\n",
        "        if idx == 0:\n",
        "            embedding = self.embed(embedding) * math.sqrt(self.d_model)\n",
        "        embedding += self.pe[:embedding.size(1), :]\n",
        "        embedding += self.te[idx, :].repeat(embedding.size(1), 1)\n",
        "        embedding = self.dropout(embedding)\n",
        "\n",
        "        return embedding"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.000314Z",
          "iopub.execute_input": "2024-03-20T16:26:29.000661Z",
          "iopub.status.idle": "2024-03-20T16:26:29.012322Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.000629Z",
          "shell.execute_reply": "2024-03-20T16:26:29.011384Z"
        },
        "trusted": true,
        "id": "rMsFWaZuINAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, heads, d_model):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % heads ==0\n",
        "\n",
        "        self.d_k = d_model//heads\n",
        "        self.heads = heads\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        self.query = nn.Linear(d_model, d_model)\n",
        "        self.key = nn.Linear(d_model, d_model)\n",
        "        self.value = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.concat = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, mask):\n",
        "\n",
        "        query = self.query(query)\n",
        "        key = self.key(key)\n",
        "        value = self.value(value)\n",
        "\n",
        "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
        "        key = key.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
        "        value = value.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
        "\n",
        "        scores = torch.matmul(query, key.permute(0, 1, 3, 2))/math.sqrt(query.shape[-1])\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        weights = F.softmax(scores, dim = -1)\n",
        "        weights = self.dropout(weights)\n",
        "\n",
        "        context = torch.matmul(weights, value)\n",
        "        context = context.permute(0, 2, 1, 3).reshape(context.shape[0], -1, self.heads*self.d_k)\n",
        "\n",
        "        interacted = self.concat(context)\n",
        "\n",
        "        return interacted"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.013562Z",
          "iopub.execute_input": "2024-03-20T16:26:29.014328Z",
          "iopub.status.idle": "2024-03-20T16:26:29.028719Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.014297Z",
          "shell.execute_reply": "2024-03-20T16:26:29.027848Z"
        },
        "trusted": true,
        "id": "pRE48Al9INAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, middle_dim = 2048):\n",
        "        super(FeedForward, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
        "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.dropout(F.relu(self.fc1(x)))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.029805Z",
          "iopub.execute_input": "2024-03-20T16:26:29.030062Z",
          "iopub.status.idle": "2024-03-20T16:26:29.041577Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.030041Z",
          "shell.execute_reply": "2024-03-20T16:26:29.040778Z"
        },
        "trusted": true,
        "id": "DlW9DDv3INAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, heads):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
        "        self.feed_forward = FeedForward(d_model)\n",
        "\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, embeddings, mask):\n",
        "\n",
        "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
        "        interacted = self.layernorm(interacted+embeddings)\n",
        "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
        "        encoded = self.layernorm(interacted+feed_forward_out)\n",
        "\n",
        "        return encoded"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.042609Z",
          "iopub.execute_input": "2024-03-20T16:26:29.042864Z",
          "iopub.status.idle": "2024-03-20T16:26:29.052187Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.042841Z",
          "shell.execute_reply": "2024-03-20T16:26:29.051353Z"
        },
        "trusted": true,
        "id": "tDG_3Ep-INAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, heads):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
        "        self.src_multihead = MultiHeadAttention(heads, d_model)\n",
        "        self.feed_forward = FeedForward(d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
        "\n",
        "        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n",
        "        query = self.layernorm(query + embeddings)\n",
        "        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n",
        "        interacted = self.layernorm(query + interacted)\n",
        "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
        "        decoded = self.layernorm(feed_forward_out + interacted)\n",
        "\n",
        "        return decoded"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.053236Z",
          "iopub.execute_input": "2024-03-20T16:26:29.053574Z",
          "iopub.status.idle": "2024-03-20T16:26:29.066314Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.05355Z",
          "shell.execute_reply": "2024-03-20T16:26:29.065498Z"
        },
        "trusted": true,
        "id": "e3VTioszINAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, heads, num_layers, word_map):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = len(word_map)\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embed = Embeddings(self.vocab_size, d_model)\n",
        "\n",
        "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
        "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n",
        "\n",
        "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
        "\n",
        "    def encode(self, src_embeddings, src_mask):\n",
        "\n",
        "        for idx, layer in enumerate(self.encoder):\n",
        "\n",
        "            src_embeddings = self.embed(src_embeddings, idx)\n",
        "            src_embeddings = layer(src_embeddings, src_mask)\n",
        "\n",
        "        return src_embeddings\n",
        "\n",
        "    def decode(self, tgt_embeddings, target_mask, src_embeddings, src_mask):\n",
        "\n",
        "        for idx, layer in enumerate(self.decoder):\n",
        "            tgt_embeddings = self.embed(tgt_embeddings, idx)\n",
        "            tgt_embeddings = layer(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
        "\n",
        "        return tgt_embeddings\n",
        "\n",
        "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
        "\n",
        "        encoded = self.encode(src_words, src_mask)\n",
        "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
        "\n",
        "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.067722Z",
          "iopub.execute_input": "2024-03-20T16:26:29.068004Z",
          "iopub.status.idle": "2024-03-20T16:26:29.078939Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.067976Z",
          "shell.execute_reply": "2024-03-20T16:26:29.078078Z"
        },
        "trusted": true,
        "id": "jDQWuKIhINAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdamWarmup:\n",
        "\n",
        "    def __init__(self, model_size, warmup_steps, optimizer):\n",
        "\n",
        "        self.model_size = model_size\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.lr = 0\n",
        "\n",
        "    def get_lr(self):\n",
        "\n",
        "        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
        "\n",
        "    def step(self):\n",
        "\n",
        "        self.current_step += 1\n",
        "        lr = self.get_lr()\n",
        "\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        self.lr = lr\n",
        "        self.optimizer.step()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.079875Z",
          "iopub.execute_input": "2024-03-20T16:26:29.080143Z",
          "iopub.status.idle": "2024-03-20T16:26:29.092424Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.080109Z",
          "shell.execute_reply": "2024-03-20T16:26:29.09169Z"
        },
        "trusted": true,
        "id": "lscKcrZUINAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LossWithLS(nn.Module):\n",
        "\n",
        "    def __init__(self, size, smooth):\n",
        "        super(LossWithLS, self).__init__()\n",
        "\n",
        "        self.criterion = nn.KLDivLoss(size_average = False, reduce = False)\n",
        "        self.size = size\n",
        "        self.smooth = smooth\n",
        "        self.confidence = 1.0 - smooth\n",
        "\n",
        "    def forward(self, prediction, target, mask):\n",
        "\n",
        "        prediction = prediction.view(-1, prediction.size(-1))\n",
        "        target = target.contiguous().view(-1)\n",
        "\n",
        "        mask = mask.float()\n",
        "        mask = mask.view(-1)\n",
        "\n",
        "        labels = prediction.data.clone()\n",
        "        labels.fill_(self.smooth/(self.size - 1))\n",
        "        labels.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "\n",
        "        loss = self.criterion(prediction, labels)\n",
        "\n",
        "        loss = (loss.sum(1)*mask).sum() / mask.sum()\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.093416Z",
          "iopub.execute_input": "2024-03-20T16:26:29.093752Z",
          "iopub.status.idle": "2024-03-20T16:26:29.109308Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.093721Z",
          "shell.execute_reply": "2024-03-20T16:26:29.108247Z"
        },
        "trusted": true,
        "id": "E9vfr4YBINAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "heads = 8\n",
        "num_layers = 6\n",
        "epochs = 5\n",
        "model_size = d_model\n",
        "warmup_steps = 4000\n",
        "\n",
        "\n",
        "with open('/kaggle/working/WORDMAP_corpus.json', 'r') as j:\n",
        "    word_map = json.load(j)\n",
        "\n",
        "size = len(word_map)\n",
        "smooth = 0.1\n",
        "\n",
        "criterion = LossWithLS(size, smooth).cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.110568Z",
          "iopub.execute_input": "2024-03-20T16:26:29.110894Z",
          "iopub.status.idle": "2024-03-20T16:26:29.136553Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.110866Z",
          "shell.execute_reply": "2024-03-20T16:26:29.135365Z"
        },
        "trusted": true,
        "id": "ugoof704INAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(d_model, heads, num_layers, word_map).cuda()\n",
        "\n",
        "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr = 0, betas = (0.9, 0.98), eps = 1e-9)\n",
        "transformer_optimizer = AdamWarmup(model_size, warmup_steps, adam_optimizer )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:29.137782Z",
          "iopub.execute_input": "2024-03-20T16:26:29.138176Z",
          "iopub.status.idle": "2024-03-20T16:26:30.515191Z",
          "shell.execute_reply.started": "2024-03-20T16:26:29.138137Z",
          "shell.execute_reply": "2024-03-20T16:26:30.514175Z"
        },
        "trusted": true,
        "id": "HhSiJX6SINAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, transformer, criterion, epoch):\n",
        "\n",
        "    transformer.train()\n",
        "\n",
        "    sum_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    for i, (question, reply) in enumerate(train_loader):\n",
        "\n",
        "        samples = question.shape[0]\n",
        "\n",
        "        question = question.cuda()\n",
        "        reply = reply.cuda()\n",
        "\n",
        "        reply_input = reply[:, :-1]\n",
        "        reply_target = reply[:, 1:]\n",
        "\n",
        "        question_mask, reply_input_mask, reply_target_mask = create_masks(question, reply_input, reply_target)\n",
        "\n",
        "        out = transformer(question, question_mask, reply_input, reply_input_mask)\n",
        "\n",
        "        loss = criterion(out, reply_target, reply_target_mask)\n",
        "\n",
        "        transformer_optimizer.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        transformer_optimizer.step()\n",
        "\n",
        "        sum_loss += loss.item() * samples\n",
        "        count += samples\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('Epoch: {}, Iterations: {}/{}, Loss: {:.3f}'.format(epoch, i, len(train_loader), sum_loss/count))\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:30.516599Z",
          "iopub.execute_input": "2024-03-20T16:26:30.516968Z",
          "iopub.status.idle": "2024-03-20T16:26:30.528157Z",
          "shell.execute_reply.started": "2024-03-20T16:26:30.516935Z",
          "shell.execute_reply": "2024-03-20T16:26:30.52696Z"
        },
        "trusted": true,
        "id": "i3LmO3IQINAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(transformer, question, question_mask, max_len, word_map):\n",
        "\n",
        "    rev_word_map = {v: k for k, v in word_map.items()}\n",
        "\n",
        "    transformer.eval()\n",
        "\n",
        "    start_token = word_map['<start>']\n",
        "\n",
        "    encoded = transformer.encode(question, question_mask)\n",
        "\n",
        "    words = torch.LongTensor([[start_token]]).cuda()\n",
        "\n",
        "    for step in range(max_len - 1):\n",
        "\n",
        "        size = words.shape[0]\n",
        "\n",
        "        target_mask = torch.tril(torch.ones(size, size)).type(dtype = torch.uint8).cuda()\n",
        "        target_mask = target_mask.unsqueeze(0).unsqueeze(1)\n",
        "\n",
        "        decoded = transformer.decode(words, target_mask, encoded, question_mask)\n",
        "\n",
        "        prediction = transformer.logit(decoded[:, -1])\n",
        "        _, next_word = torch.max(prediction, dim = -1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        if next_word == word_map['<end>']:\n",
        "            break\n",
        "        words = torch.cat([words, torch.LongTensor([[next_word]]).cuda()], dim = -1)\n",
        "\n",
        "    words = words.squeeze(0)\n",
        "    words = words.tolist()\n",
        "\n",
        "    sen_idx = [w for w in words if w != word_map['<start>']]\n",
        "    sentence = \" \".join([rev_word_map[w] for w in sen_idx])\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:30.529644Z",
          "iopub.execute_input": "2024-03-20T16:26:30.530815Z",
          "iopub.status.idle": "2024-03-20T16:26:30.543549Z",
          "shell.execute_reply.started": "2024-03-20T16:26:30.530634Z",
          "shell.execute_reply": "2024-03-20T16:26:30.542655Z"
        },
        "trusted": true,
        "id": "9F0ODpcGINAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoint = torch.load('/kaggle/input/transformer/checkpoint9.pth')\n",
        "#transformer = checkpoint['transformer']\n",
        "#transformer_optimizer = checkpoint['transformer_optimizer']\n",
        "#epoch = checkpoint['epoch']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:30.545133Z",
          "iopub.execute_input": "2024-03-20T16:26:30.545433Z",
          "iopub.status.idle": "2024-03-20T16:26:30.55573Z",
          "shell.execute_reply.started": "2024-03-20T16:26:30.545408Z",
          "shell.execute_reply": "2024-03-20T16:26:30.554878Z"
        },
        "trusted": true,
        "id": "4CePwwJhINAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    train(train_loader, transformer, criterion, epoch)\n",
        "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
        "torch.save(state, 'checkpoint'+str(epoch)+'.pth')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:26:30.556983Z",
          "iopub.execute_input": "2024-03-20T16:26:30.55724Z",
          "iopub.status.idle": "2024-03-20T16:27:11.407079Z",
          "shell.execute_reply.started": "2024-03-20T16:26:30.557218Z",
          "shell.execute_reply": "2024-03-20T16:27:11.405788Z"
        },
        "trusted": true,
        "id": "VcHgLrKdINAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    question = 'How are you doing'\n",
        "    max_len = 21\n",
        "    enc_ques = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n",
        "    question = torch.tensor(enc_ques).cuda().unsqueeze(0)\n",
        "    question_mask = (question !=0).cuda().unsqueeze(1).unsqueeze(1)\n",
        "    sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n",
        "    print(sentence)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T16:27:11.408079Z",
          "iopub.status.idle": "2024-03-20T16:27:11.408488Z",
          "shell.execute_reply.started": "2024-03-20T16:27:11.408285Z",
          "shell.execute_reply": "2024-03-20T16:27:11.4083Z"
        },
        "trusted": true,
        "id": "QsSpPEdRINAd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}